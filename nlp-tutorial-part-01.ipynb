{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words Meets Bags of Popcorn\n",
    "- https://www.kaggle.com/c/word2vec-nlp-tutorial\n",
    "- 튜토리얼을 제공하는 케글 경진대회 중의 하나\n",
    "\n",
    "#### [자연 언어 처리 - 위키백과, 우리 모두의 백과사전](https://ko.wikipedia.org/wiki/%EC%9E%90%EC%97%B0_%EC%96%B8%EC%96%B4_%EC%B2%98%EB%A6%AC)\n",
    "- 자연 언어 처리(自然言語處理) 또는 자연어 처리(自然語處理)는 인간이 발화하는 언어 현상을 기계적으로 분석해서 컴퓨터가 이해할 수 있는 형태로 만드는 자연 언어 이해 혹은 그러한 형태를 다시 인간이 이해할 수 있는 언어로 표현하는 제반 기술을 의미한다. (출처 : 위키피디아)\n",
    "\n",
    "#### 자연어처리(NLP)와 관련된 캐글 경진대회\n",
    "- [Sentiment Analysis on Movie Reviews | Kaggle](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews)\n",
    "- [Toxic Comment Classification Challenge | Kaggle](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)\n",
    "- [Spooky Author Identification | Kaggle](https://www.kaggle.com/c/spooky-author-identification)\n",
    "\n",
    "## 튜토리얼 개요\n",
    "\n",
    "### 파트1\n",
    "- 입문자를 대상으로 기본 자연어 처리(Bag Of Words)를 다룬다.\n",
    "\n",
    "### 파트2, 3\n",
    "- Word2Vec을 사용하여(Word Vectors) 모델을 학습시키는 방법과 감정분석에 단어 벡터를 사용하는 방법을 본다.\n",
    "- 파트3는 레시피를 제공하지 않고 Word2Vec을 사용하는 몇 가지 방법을 실험해 본다.\n",
    "- 파트3에서는 K-means 알고리즘을 사용해 군집화를 해본다.\n",
    "- 긍정과 부정 리뷰가 섞여있는 100,000만개의 IMDB 감정분석 데이터 세트를 통해 목표를 달성해 본다.\n",
    "\n",
    "### 평가 - ROC 커브(Receiver-Operating Characteristic curve)\n",
    "- **TPR**(True Positive Rate)과 **FPR**(False Positive Rate)을 각각 x, y 축으로 놓은 그래프\n",
    "- **민감도 TPR**\n",
    "    - **1인 케이스에 대해 1로 예측한 비율**\n",
    "    - 암환자를 진찰해서 암이라고 진단함\n",
    "- **특이도 FPR**\n",
    "    - **0인 케이스에 대해 1로 잘못 예측한 비율**\n",
    "    - 암환자가 아닌데 암이라고 진단함\n",
    "- X, Y가 둘 다 [0, 1] 범위이고 (0, 0)에서 (1, 1)을 잇는 곡선이다.\n",
    "<img src=\"img/01_roc.png\" width=\"350\">(출처 : 위키피디아)\n",
    "- **ROC 커브의 및 면적이 1에 가까울 수록(왼쪽 꼭지점에 다가갈수록) 좋은 성능(정확도가 높은 평가 방법이다)**\n",
    "- 참고 :\n",
    "    - [New Sight :: Roc curve, AUR(AUCOC), 민감도, 특이도](http://newsight.tistory.com/53)\n",
    "    - [ROC의 AUC 구하기 :: 진화하자 - 어디에도 소속되지 않기](http://adnoctum.tistory.com/121)\n",
    "    - [Receiver operating characteristic - Wikipedia](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)\n",
    "    \n",
    "### Use Google's Word2Vec for movie reviews\n",
    "- 자연어 텍스트를 분석해서 특정단어를 얼마나 사용했는지, 얼마나 자주 사용했는지, 어떤 종류의 텍스트인지 분류하거나 긍정인지 부정인지에 대한 감정분석, 그리고 어떤 내용인지 요약하는 정보를 얻을 수 있다.\n",
    "- 감정분석은 머신러닝(기계학습)에서 어려운 주제로 풍자, 애매모호한 말, 반어법, 언어 유희로 표현을 하는데 이는 사람과 컴퓨터에게 모두 오해의 소지가 있다. 여기에서는 Word2Vec을 통한 감정분석을 해보는 튜토리얼을 해본다.\n",
    "- Google의 Word2Vec은 단어의 의미와 관계를 이해하는 데 도움\n",
    "- 상당수의 NLP기능은 nltk모듈에 구현되어 있는데 이 모듈은 코퍼스, 함수와 알고리즘으로 구성되어 있다.\n",
    "- 단어 임베딩 모형 테스트 : [Korean Word2Vec](http://w.elnn.kr/search/)\n",
    "\n",
    "### BOW(bag of words)\n",
    "- 가장 간단하지만 효과적이라 널리쓰이는 방법\n",
    "- 장, 문단, 문장, 서식과 같은 입력 텍스트의 구조를 제외하고 각 단어가 이 말뭉치에 얼마나 많이 나타나는지만 헤아린다.\n",
    "- 구조와 상관없이 단어의 출현횟수만 세기 때문에 텍스트를 담는 가방(bag)으로 생각할 수 있다.\n",
    "- BOW는 단어의 순서가 완전히 무시 된다는 단점이 있다. 예를 들어 의미가 완전히 반대인 두 문장이 있다고 하다.\n",
    "    - `it's bad, not good at all.`\n",
    "    - `it's good, not bad at all.`\n",
    "- 위 두 문장은 의미가 전혀 반대지만 완전히 동일하게 반환된다.\n",
    "- **이를 보완하기 위해 n-gram을 사용**하는 데 BOW는 하나의 토큰을 사용하지만 n-gram은 n개의 토큰을 사용할 수 있도록 한다.\n",
    "\n",
    "* [Bag-of-words model - Wikipedia](https://en.wikipedia.org/wiki/Bag-of-words_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 파트 1\n",
    "\n",
    "- **NLP는?**<br>\n",
    "NLP(자연어처리)는 텍스트 문제에 접근하기 위한 기술집합이다.\n",
    "<br>\n",
    "<br>\n",
    "- 이 튜토리얼에서는 IMDB 영화 리뷰를 로딩하고 정제하고 간단한 BOW(Bag of Words) 모델을 적용하여 리뷰가 추천인지 아닌지에 대한 정확도를 예측한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\"\"\"\n",
    "header = 0 은 파일의 첫 번째 줄에 열 이름이 있음을 나타내며 \n",
    "delimiter = \\t 는 필드가 탭으로 구분되는 것을 의미한다.\n",
    "quoting = 3은 쌍따옴표를 무시하도록 한다.\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\"At eight o'clock on Thursday morning Arthur didn't feel very good.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['At',\n",
       " 'eight',\n",
       " \"o'clock\",\n",
       " 'on',\n",
       " 'Thursday',\n",
       " 'morning',\n",
       " 'Arthur',\n",
       " 'did',\n",
       " \"n't\",\n",
       " 'feel',\n",
       " 'very',\n",
       " 'good',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(sentence)\n",
    "tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('At', 'IN'),\n",
       " ('eight', 'CD'),\n",
       " (\"o'clock\", 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('Thursday', 'NNP'),\n",
       " ('morning', 'NN'),\n",
       " ('Arthur', 'NNP'),\n",
       " ('did', 'VBD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('feel', 'VB'),\n",
       " ('very', 'RB'),\n",
       " ('good', 'JJ'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(tokens)\n",
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# %ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/labeledTrainData.tsv',\n",
    "                   header=0, delimiter='\\t', quoting=3)\n",
    "train.shape\n",
    "\n",
    "test = pd.read_csv('data/testData.tsv',\n",
    "                   header=0, delimiter='\\t', quoting=3)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>\"3453_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It seems like more consideration has gone int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>\"5064_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"I don't believe they made this film. Complete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>\"10905_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Guy is a loser. Can't get girls, needs to bui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>\"10194_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"This 30 minute documentary Buñuel made in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>\"8478_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"I saw this movie as a child and it broke my h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  sentiment                                             review\n",
       "24995   \"3453_3\"          0  \"It seems like more consideration has gone int...\n",
       "24996   \"5064_1\"          0  \"I don't believe they made this film. Complete...\n",
       "24997  \"10905_3\"          0  \"Guy is a loser. Can't get girls, needs to bui...\n",
       "24998  \"10194_3\"          0  \"This 30 minute documentary Buñuel made in the...\n",
       "24999   \"8478_8\"          1  \"I saw this movie as a child and it broke my h..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>\"2155_10\"</td>\n",
       "      <td>\"Sony Pictures Classics, I'm looking at you! S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>\"59_10\"</td>\n",
       "      <td>\"I always felt that Ms. Merkerson had never go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>\"2531_1\"</td>\n",
       "      <td>\"I was so disappointed in this movie. I am ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>\"7772_8\"</td>\n",
       "      <td>\"From the opening sequence, filled with black ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>\"11465_10\"</td>\n",
       "      <td>\"This is a great horror film for people who do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                             review\n",
       "24995   \"2155_10\"  \"Sony Pictures Classics, I'm looking at you! S...\n",
       "24996     \"59_10\"  \"I always felt that Ms. Merkerson had never go...\n",
       "24997    \"2531_1\"  \"I was so disappointed in this movie. I am ver...\n",
       "24998    \"7772_8\"  \"From the opening sequence, filled with black ...\n",
       "24999  \"11465_10\"  \"This is a great horror film for people who do..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'sentiment', 'review'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 레이블인 'sentiment'가 없다. 이 데이터를 기계학습을 통해 예측한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'review'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns.values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
